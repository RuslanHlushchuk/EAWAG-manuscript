---
title: Microtomographic investigation of a large corpus of cichlids
keywords:
- cichlids
- x-ray micro-tomography
lang: en-US
date-meta: '2022-09-30'
author-meta:
- David Haberthür
- Mikki Law
- Kassandra Ford
- Marcel Häsler
- Ole Seehausen
- Ruslan Hlushchuk
header-includes: |-
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Microtomographic investigation of a large corpus of cichlids" />
  <meta name="citation_title" content="Microtomographic investigation of a large corpus of cichlids" />
  <meta property="og:title" content="Microtomographic investigation of a large corpus of cichlids" />
  <meta property="twitter:title" content="Microtomographic investigation of a large corpus of cichlids" />
  <meta name="dc.date" content="2022-09-30" />
  <meta name="citation_publication_date" content="2022-09-30" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="David Haberthür" />
  <meta name="citation_author_institution" content="Institute of Anatomy, Unversity of Bern, Switzerland" />
  <meta name="citation_author_orcid" content="0000-0003-3388-9187" />
  <meta name="twitter:creator" content="@habi" />
  <meta name="citation_author" content="Mikki Law" />
  <meta name="citation_author_institution" content="None" />
  <meta name="citation_author_orcid" content="None" />
  <meta name="citation_author" content="Kassandra Ford" />
  <meta name="citation_author_institution" content="None" />
  <meta name="citation_author_orcid" content="None" />
  <meta name="citation_author" content="Marcel Häsler" />
  <meta name="citation_author_institution" content="None" />
  <meta name="citation_author_orcid" content="None" />
  <meta name="citation_author" content="Ole Seehausen" />
  <meta name="citation_author_institution" content="None" />
  <meta name="citation_author_orcid" content="None" />
  <meta name="citation_author" content="Ruslan Hlushchuk" />
  <meta name="citation_author_institution" content="Institute of Anatomy, Unversity of Bern, Switzerland" />
  <meta name="citation_author_orcid" content="None" />
  <link rel="canonical" href="https://habi.github.io/EAWAG-manuscript/" />
  <meta property="og:url" content="https://habi.github.io/EAWAG-manuscript/" />
  <meta property="twitter:url" content="https://habi.github.io/EAWAG-manuscript/" />
  <meta name="citation_fulltext_html_url" content="https://habi.github.io/EAWAG-manuscript/" />
  <meta name="citation_pdf_url" content="https://habi.github.io/EAWAG-manuscript/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://habi.github.io/EAWAG-manuscript/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://habi.github.io/EAWAG-manuscript/v/6cf8ebfd187f243bc4ac4e72f968c69aae701116/" />
  <meta name="manubot_html_url_versioned" content="https://habi.github.io/EAWAG-manuscript/v/6cf8ebfd187f243bc4ac4e72f968c69aae701116/" />
  <meta name="manubot_pdf_url_versioned" content="https://habi.github.io/EAWAG-manuscript/v/6cf8ebfd187f243bc4ac4e72f968c69aae701116/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
bibliography:
- content/manual-references.json
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
manubot-clear-requests-cache: false
...






<small><em>
This manuscript
([permalink](https://habi.github.io/EAWAG-manuscript/v/6cf8ebfd187f243bc4ac4e72f968c69aae701116/))
was automatically generated
from [habi/EAWAG-manuscript@6cf8ebf](https://github.com/habi/EAWAG-manuscript/tree/6cf8ebfd187f243bc4ac4e72f968c69aae701116)
on September 30, 2022.
</em></small>

## Authors



+ **David Haberthür**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon width=16 height=16}
    [0000-0003-3388-9187](https://orcid.org/0000-0003-3388-9187)
    · ![GitHub icon](images/github.svg){.inline_icon width=16 height=16}
    [habi](https://github.com/habi)
    · ![Twitter icon](images/twitter.svg){.inline_icon width=16 height=16}
    [habi](https://twitter.com/habi)<br>
  <small>
     Institute of Anatomy, Unversity of Bern, Switzerland
  </small>

+ **Mikki Law**<br><br>
  <small>
     None
  </small>

+ **Kassandra Ford**<br><br>
  <small>
     None
  </small>

+ **Marcel Häsler**<br><br>
  <small>
     None
  </small>

+ **Ole Seehausen**<br><br>
  <small>
     None
  </small>

+ **Ruslan Hlushchuk**<br><br>
  <small>
     Institute of Anatomy, Unversity of Bern, Switzerland
  </small>



## Abstract {.page_break_before}

A large corpus of Cichlids from Lake Victoria in Africa spanning a size range of 6 to 20 cm was nondestructively imaged using micro-computed tomography.
The presented manuscript describes a method to efficiently obtain three-dimensional tomographic data sets of the oral and pharyngeal jaws and the whole skull of these fishes.
We describe in detail how the data has been acquired to aid in reproducible research.
The tomographic data we acquired (8.8 TB projection images) was reconstructed into 1.4 TB of three-dimensional images which are used for further projects.
Herein we present our method and an outlook on two projects analyzing the acquired data; a morphological description of the oral and pharyngeal jaws of the fishes as well as a principal component analysis of landmark features on the fish skulls.

## Introduction {.page_break_before}

### History

- Cichlids from Lake Victoria
- Sample 'library' of EAWAG
- Valuable, hence non-destructive imaging is *paramount*

[TODO]: # (Add some information on the backstory of those fishes, and maybe publications relating to the corpus of fishes)

### micro-CT

X-ray microtomography is a valuable tool to gain insights into the inner structure of very diverse samples, namely for specimens related to research done in the biomedical sciences.
Namely in the 'fish sciences', X-ray microtomography has been employed as a method of choice to non-destructively assess the morphology of various samples [@https://osf.io/ecmz4] ^[For which David made a tomographic scan of an adult zebrafish ages ago.]

Depending on the structures of interest biomedical samples are often tomographically scanned after the tissue/sample has been stained with a contrast agent, most often employing contrast agents containing heavy metals.
Since the structures of interest for the two studies we touch upon in this manuscript (Cichlids teeth and skull bones) display large enough contrast to the surrounding tissue we did not stain our samples prior to the tomographic imaging presented here.

[TODO]: # (Mention the `fishguy` some more? [@https://www.washington.edu/storycentral/story/uw-professor-is-digitizing-every-fish-species-in-the-world].)

## Materials and Methods {.page_break_before}
### Sample procurement and preparation

The fishes were kept in 75% Ethanol for long-term storage in the EAWAG fish library.
They were delivered to the Institute of Anatomy for X-ray microtomography investigation sorted into several batches by approximately equal length.

[TODO]: # (Were they transported to Bern as 'Gefahrengut'-Transport? This would be a remarkable little tidbit to add to the manuscript)

### micro-CT imaging

All samples were scanned on two of the three available high-resolution 3D X-ray microtomography scanners of the Institute of Anatomy of the University of Bern in Switzerland, a SkyScan 1272 and a SkyScan 2214 (both Bruker microCT, Kontich, Belgium).

The fishes were sorted into 'bins' based on their physical size.
We used a custom-made sample-holder to scan each of the fish in our machines.
A sample holder was 3D-printed on a Form 2 desktop stereolithography printer (Formlabs, Somerville, Massachusetts, USA) and is freely available online [@https://github.com/TomoGraphics/Hol3Drs/blob/master/STL/EAWAG.Fish.stl] as part of a library of sample holders for tomographic scanning of biomedical samples [@doi:10.5281/zenodo.2587555].
The sample holder was custom-made for this project and is easily parametrized to the different width, height and length classes of the fishes.

In total, we acquired 340 tomographic scans of 127 different fishes.
All the scanning parameters are collected in a table in the [Supplementary Materials], a generalized rundown is given below.

Since the fishes greatly varied in their length, the voxel sizes of each of the acquired datasets also varies greatly.
We acquired datasets with (isometric) voxel sizes ranging from 3--50 μm.

Depending on the size of the specimen we set the x-ray source voltage to 50--80 kV and---depending on the voltage---to a current between 107 and 200 μA.
Also depending on the size of the fishes, the x-ray spectrum was filtered either by an Aluminum filter of varying thickness (either 0.25, 0.5 or 1 mm) before digitization to projection images or recorded in an unfiltered way.
I total we recorded 8.8 TB of projections images (`*.?if` files) for this project.

All the recorded projection images were subsequently reconstructed into a 3D stack of axial PNG images spanning the regions of interest of each fish.
Since all the specimens were scanned with their mouths downward and rotating along their long axis, we manually rotated each of the reconstructed datasets so that the lateral axis through the fish was horizontal in relation to the x and y direction of each reconstructed slice.
We reconstructed the projection images with NRecon (Version 1.7.4.6, Bruker microCT, Kontich Belgium) with varying ring artifact and beam hardening correction values, depending on each fish (again, all relevant values are listed in the [Supplementary Materials]).
In total, this resulted in 1.4 TB of reconstruction images (`*rec*.png` files).

While performing the work, a subset of the data was always present on the production system, for working with it (see [Preparation for analysis
] below).
A small bash script [@https://github.com/habi/EAWAG/blob/master/rsync-fishes.sh] was used to generate redundant (archival) copies of the raw projection images and copy all the files to a shared network drive on the `research_storage` infrastructure of the University of Bern, enabling easy collaboration on the data by all co-authors at the same time.

[TODO]: # (I *still* would like to be able to make as much data as possible accessible to other researchers. Can we don this as part of this manuscript?)

### Data analysis

We wrote a set of *Jupyter* [@https://eprints.soton.ac.uk/403913] notebooks with *Python* code to work with the images and wrangle the acquired data.
The notebooks were written at the start of the project, to be able to process new scans as soon as they were reconstructed.
Re-runs of the notebook added newly scanned and reconstructed fishes to the analysis, facilitating a an efficient quality check of the scans and batched processing of the data.

All Jupyter notebooks for this work are available online [@doi:10.5281/zenodo.6798632].

#### Preparation for analysis

The main Jupyter notebook for this manuscript dealt with reading all log and image files and preparing images for quality checking and the next steps.
Briefly summarized the below process was implemented.

At first, *all* log files of *all* the scans were read into a list (*all* data of the notebook was saved into a `pandas` [@doi:10.5281/zenodo.7093122] dataframe).
This already enabled us to extract the specimen name and scan, since we performed several scans for each specimen, e.g. a low resolution scan with large field of view for the whole head and one or several scans in high resolution focusing on the region of the oral and pharyngeal scans.
From the log files we extracted the relevant values for double-checking the necessary parameters of each scan.
All relevant values for each scan were also saved into the dataframe and saved out to the aforementioned table in the [Supplementary Materials] at the end of each run of the notebook.

After several 'sanity checks' of the data, we used `Dask` [@dask] to efficiently access the very large total amount of axial reconstruction PNG slices for this project (in the end a total of nearly a million single slices).
On average, each of the tomographic datasets contains around 3000 slices, so the total amount of data is much too large to keep in memory.
The use of the *Dask* library facilitated efficient (so-called lazy) access to the huge amount of data on disk.

At first, we extracted the central view of each of the three axial directions of the datasets, e.g. the 'anteroposterior', 'lateral' and 'dorsoventral' view and either saved those to disk or loaded them if already generated in prior runs of the notebook.
The notebook then also generated the maximum intensity projection (MIP) for each of the anatomical planes and either saved them to disk or loaded them from prior runs.

At the end of the notebook we performed a final sanity check on the MIP images.
In this check we examined the mapping of the gray values of the raw projection images to gray values in the reconstructions, e.g. checked that no overexposed pixels are present in the MIP images, which is an efficient way of checking this, since the MIP images have already been generated in prior steps of the notebook.

### Image processing
#### Extraction of oral and pharyngeal jaws, visualization of tomographic data

To extract the oral jaw (OJ) and pharyngeal jaw (PJ) of the fishes, we used [3DSlicer](https://www.slicer.org) (Version 4.11.20210226) [@doi:10.1016/j.mri.2012.05.001] extended with the SlicerMorph tools [@doi:10.1111/2041-210X.13669] which help biologists to work with 3D specimen data.
The reconstructed `.png` stacks were loaded into ImageStacks, depending on their size we reduced the image resolution (e.g. downscaled the images) for this first step.
The three-dimensional volume was rendered via [VTK GPU Ray Casting](https://slicer.readthedocs.io/en/latest/user_guide/modules/volumerendering.html).
A custom-made volume property (created by Kassandra Ford) was used as an input to view the scans.
Using toggles in the volume rendering, we defined regions of interest (ROIs) for both the OJs and PJs in each specimen..
These ROIs were then extracted in their native resolution from the original dataset for further processing.
Using the grayvalue thresholding function in Slicers Segment Editor the teeth in both the oral and pharyngeal jaws were extracted.
We used the 'Scissor' and 'Island' tools of the Segment Editor to isolate single regions.

Processed regions of interest were exported as NRRD [@https://w.wiki/5mBK] files.
The three-dimensional visualizations of all regions of interest for each specimen were compiled into overview images (see Figure @fig:kat13pptx for an example from the compilation document).
In total we compiled overview of XXX specimens with full head morphology, oral jaw and lower pharyngeal jaw profiles.

![Overview of data from 'KAT-13, Lake Edward, "Thoracochromis" pharyngalis (pharyngeal mollusc crusher – shrimp)'](images/KAT13.pptx.png){#fig:kat13pptx}

[TODO]: # (Do we really need to specify 'created by Kassandra Ford' for the custom-made property?)
[TODO]: # (Accurate specimen number in .pptx file from Mikki. The PPTX file `CT scan slides_ML_March26_2022.pptx` contains 112 slides...)

#### Principal component analysis of skull landmarks

- Very superficial description of principal component analysis (?) from Kassandra.
  We do *not* want to cannibalize her upcoming manuscript, but only hint at what will be done.

#### Automatic extraction of otoliths

- Notebook: `EAWAG/ExtractOtoliths.ipynb`
- MIPs are oriented *anteroposterior*, *lateral* and *dorsoventral*
- Simple grayvalue plot along the longest axis
- Find peak of this grayvalue 
- otolith is around maximum gray value along fish, (see Figure @fig:otolither)

![Automatic otolith extraction.](images/10619.head_rec_unbinned_17.5um.Otolither.png){#fig:otolither}

## Results {.page_break_before}

- A lot of fishes
- A lot of scans
- A lot of data

#### Automatic extraction of otoliths

![Result of automatic otolith extraction. Three-dimensional view of extracted otolith.](images/Otolith-3D.png){#fig:otolith3d}

## Discussion {.page_break_before}

The discussion of the results and the outlook to what we'll do in the future is going into this file here.


## Acknowledgments {.page_break_before}

We thank the `manubot` project [@doi:10.1371/journal.pcbi.1007128] for helping us write this manuscript collaboratively.

[TODO]: # (Do we need to include more persons here, according to: https://www.rms.org.uk/community/networks-affiliates/bioimaginguk-network/imaging-facility-publication-guidelines.html)

## Supplementary Materials {.page_break_before}

### Parameters of tomographic scans of all the fishes
The CSV file [ScanningDetails.csv](https://github.com/habi/EAWAG-manuscript/blob/main/content/data/ScanningDetails.csv) gives a tabular overview of all the (relevant) parameters of all the scans we performed.
This file was generated with the [data processing notebook](https://github.com/habi/EAWAG/blob/master/DataWrangling.ipynb) and contains the data which is read from *all* the log files of *all* the scans we performed.
A copy of the log files is available in a [folder in the data processing repository](https://github.com/habi/EAWAG/tree/master/logfiles).

## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
